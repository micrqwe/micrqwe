id: 202006231110
title: 问题故障解析
date: 2021-03-26 09:12:08
tags: "java开发"
---------

# mq故障

1. 事故现象：服务开始出现请求缓慢，进而系统全面崩溃
```$xslt
8:00，收到系统故障提醒,并立即进行故障的排查； 
8:00至16:00，分析问题，从CPU、内存、连接数量、系统日志等进行分析均未发现明显异常，
尝试各种解决方案，包括限流、熔断、服务降级、服务重启等均无法有效解决； 
16:00, 发现到消息队列服务器有阻塞现象，对消息队列服务器进行重启； 
16:30，完成所有相关的服务器重启，系统恢复正常，并开始验证服务的稳定性； 
17:20，对外恢复服务； 
```

2. 问题出现原因。
```$xslt
1. 出现问题原因在于生产者发送消息过快，mq出现消息堆积，同时消费者处理过慢。
2. 由于消息持续堆积引发了rabbitmq自己的保护机制，开始阻塞生产者写入消息。
3. 生产者开启的是线程，线程被阻塞无法释放，线程不断开启，重启服务后没过几分钟服务又开始宕机。
4. 虽然看见mq消费堆积，服务重启后依然在不断消费，所以还未察觉到是mq有问题。
5. mq的阻塞写入造成一个循环，消费慢，写入快，系统服务级联反应。造成系统持续不可用。
```

3. 执行过程。
```$xslt
1. 线上出现问题，第一要点保证服务尽快可用。
2. 对于中间件重启，第一要点恢复数据，防止数据丢失。
3. mq由于本次消费堆积，进行了和相应业务方对接，对mq消息进行区分。哪些可以直接删除(需要参照业务)。哪些重新导出写脚本进行补偿。
4. mq重启后服务一切正常，系统恢复可用状态
```

rabbitmq阻塞说明:https://cloud.tencent.com/developer/article/1454194
```$xslt
1. 因为RabbitMQ服务器在启动时会计算系统内存总大小。然后会根据vm_memory_high_watermark参数指定的百分比，进行控制
2. 当RabbitMQ的磁盘空闲空间小于50M（默认），生产者将被BLOCK，并且阻塞信息发布前，会尝试把内存中的信息输出到磁盘上
```

# redis故障

1. 事故现象：个别服务大量redis timeout。导致涉及缓存接口不可用。
```$xslt
1. 重启redis，数据抓紧恢复，影响1小时
```

2. 问题出现原因。本次问题出现为3个原因进行叠加。
```$xslt
1. redis存在大量的大key，导致redis服务的压力过大。
2. 中间件的不合理，由于开发者不了解jedis，对jedis在外面在包装一个线程池，导致线程池套用线程池。redis服务的tcp连接非常多。
3. redis目前为共享一个，线上服务多。最终问题出现压垮了redis。
```
